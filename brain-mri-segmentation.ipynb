{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MRI Brain Cancer Segmentation with UNet","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:57:54.904254Z","iopub.execute_input":"2021-10-30T11:57:54.904675Z","iopub.status.idle":"2021-10-30T11:58:00.202695Z","shell.execute_reply.started":"2021-10-30T11:57:54.904586Z","shell.execute_reply":"2021-10-30T11:58:00.201958Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# utils\nimage_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n\n\ndef list_images(base_path,contains=None):\n    # return the set of files that are valid\n    return list_files(base_path, valid_exts=image_types, contains=contains)\n\ndef list_files(base_path, valid_exts=None, contains=None):\n    # loop over the directory structure\n    for (root_dir, dir_names, filenames) in os.walk(base_path):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if valid_exts is None or ext.endswith(valid_exts):\n                # construct the path to the image and yield it\n                image_path = os.path.join(root_dir, filename)\n                yield image_path","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:00.204370Z","iopub.execute_input":"2021-10-30T11:58:00.204636Z","iopub.status.idle":"2021-10-30T11:58:00.211969Z","shell.execute_reply.started":"2021-10-30T11:58:00.204603Z","shell.execute_reply":"2021-10-30T11:58:00.211411Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"\n\nTRAIN_SPLIT=0.8\nVAL_SPLIT=0.1  # % from training dataset\n\nIMG_SIZE=(256,256)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:00.213112Z","iopub.execute_input":"2021-10-30T11:58:00.213512Z","iopub.status.idle":"2021-10-30T11:58:00.248171Z","shell.execute_reply.started":"2021-10-30T11:58:00.213469Z","shell.execute_reply":"2021-10-30T11:58:00.247421Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Exploring dataset","metadata":{}},{"cell_type":"code","source":"image_paths=list(list_images(DATA_PATH))\n\ndataset=pd.DataFrame(image_paths, columns=['filepath'])\n\nprint(dataset.filepath[0])\nprint(dataset.filepath[100])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:00.250293Z","iopub.execute_input":"2021-10-30T11:58:00.250825Z","iopub.status.idle":"2021-10-30T11:58:01.950980Z","shell.execute_reply.started":"2021-10-30T11:58:00.250790Z","shell.execute_reply":"2021-10-30T11:58:01.950074Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# check if filepath contains \"mask\"\nimages=dataset[~dataset[\"filepath\"].str.contains(\"mask\")]\nmasks=dataset[dataset[\"filepath\"].str.contains(\"mask\")]\n\n# Sorting images\nbase_len=len('/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_')\nimg_len=len('.tif')\nmask_len=len('_mask.tif')\n\nimages=sorted(images.filepath.values,key=lambda p : int(p[base_len:-img_len]))\nmasks=sorted(masks.filepath.values,key=lambda p : int(p[base_len:-mask_len]))\nprint(images[150])\nprint(masks[150])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:01.952317Z","iopub.execute_input":"2021-10-30T11:58:01.952635Z","iopub.status.idle":"2021-10-30T11:58:01.981729Z","shell.execute_reply.started":"2021-10-30T11:58:01.952592Z","shell.execute_reply":"2021-10-30T11:58:01.981051Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"patients=[i.split('/')[5] for i in images]\nprint(patients[2])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:01.982774Z","iopub.execute_input":"2021-10-30T11:58:01.983041Z","iopub.status.idle":"2021-10-30T11:58:01.989930Z","shell.execute_reply.started":"2021-10-30T11:58:01.982998Z","shell.execute_reply":"2021-10-30T11:58:01.988921Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"mask1=cv2.imread(masks[0])\nmask2=cv2.imread(masks[1500])\nfig,ax=plt.subplots(1,2)\nax[0].imshow(mask1)\nax[1].imshow(mask2)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:01.991477Z","iopub.execute_input":"2021-10-30T11:58:01.992003Z","iopub.status.idle":"2021-10-30T11:58:02.473629Z","shell.execute_reply.started":"2021-10-30T11:58:01.991904Z","shell.execute_reply":"2021-10-30T11:58:02.472958Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\ndef diagnosis(path):\n    '''Mask with fill with zeros is negative. Mask with a region of ones is positive.'''\n    value = np.max(cv2.imread(path))\n    if value > 0 : return 1\n    else: return 0\n    \ndataset=pd.DataFrame({\n    \"patient\": patients,\n    \"image_path\":images,\n    \"mask_path\": masks,\n})\n\ndataset[\"diagnosis\"]=dataset[\"mask_path\"].apply(lambda path:diagnosis(path))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:02.474982Z","iopub.execute_input":"2021-10-30T11:58:02.475264Z","iopub.status.idle":"2021-10-30T11:58:26.421522Z","shell.execute_reply.started":"2021-10-30T11:58:02.475229Z","shell.execute_reply":"2021-10-30T11:58:26.420764Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(dataset.head())\nprint()\nprint(dataset.info())\nprint()\nprint(\"Number of negative (0) and positive (1) cases:\")\nprint(dataset.diagnosis.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:26.422904Z","iopub.execute_input":"2021-10-30T11:58:26.423152Z","iopub.status.idle":"2021-10-30T11:58:26.446544Z","shell.execute_reply.started":"2021-10-30T11:58:26.423119Z","shell.execute_reply":"2021-10-30T11:58:26.445862Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Plot some images and mask\npositive=dataset[dataset[\"diagnosis\"]==1].iloc[100]\nnegative=dataset[dataset[\"diagnosis\"]==0].iloc[100]\n\nfig, (ax1, ax2)=plt.subplots(2,3,figsize=(25., 25.))\nimg_pos=cv2.imread(positive[\"image_path\"])\nmask_pos=cv2.imread(positive[\"mask_path\"])\nax1[0].imshow(img_pos)\nax1[1].imshow(img_pos[:,:,0], cmap='hot')\nax1[2].imshow(mask_pos)\n\nimg_neg=cv2.imread(negative[\"image_path\"])\nmask_neg=cv2.imread(negative[\"mask_path\"])\nax2[0].imshow(img_neg)\nax2[1].imshow(img_neg[:,:,0], cmap='hot')\nax2[2].imshow(mask_neg)\n\n    \nprint(img_pos.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:26.449213Z","iopub.execute_input":"2021-10-30T11:58:26.449771Z","iopub.status.idle":"2021-10-30T11:58:27.701632Z","shell.execute_reply.started":"2021-10-30T11:58:26.449743Z","shell.execute_reply":"2021-10-30T11:58:27.700996Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#compute the training and testing split\ntrain,test=train_test_split(dataset, train_size=TRAIN_SPLIT,stratify=dataset[\"diagnosis\"])\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\n#split for validation\ntrain,val=train_test_split(train, test_size=VAL_SPLIT,stratify=train[\"diagnosis\"])\ntrain = train.reset_index(drop=True)\nval = val.reset_index(drop=True)\n\nTRAIN_SIZE=len(train)\nVAL_SIZE=len(val)\nTEST_SIZE=len(test)\nprint(\"Training dataset size: {}\".format(TRAIN_SIZE))\nprint(\"Validation dataset size: {}\".format(VAL_SIZE))\nprint(\"Testing dataset size: {}\".format(TEST_SIZE))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:27.702571Z","iopub.execute_input":"2021-10-30T11:58:27.702810Z","iopub.status.idle":"2021-10-30T11:58:27.728830Z","shell.execute_reply.started":"2021-10-30T11:58:27.702779Z","shell.execute_reply":"2021-10-30T11:58:27.728084Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def dataloader(dataframe, batch_size, target_size, aug_params):\n    SEED=5\n    \n    img_datagenerator=ImageDataGenerator(**aug_params)\n    mask_datagenerator=ImageDataGenerator(**aug_params)\n      \n    image_generator = img_datagenerator.flow_from_dataframe(\n        dataframe,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = 'rgb',\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = None,\n        seed = SEED)\n\n    mask_generator = mask_datagenerator.flow_from_dataframe(\n        dataframe,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = 'grayscale',\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = None,\n        seed = SEED)\n\n    gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in gen:\n        img = img / 255.\n        mask = mask / 255.\n        mask[mask > 0.5] = 1\n        mask[mask <= 0.5] = 0\n        yield (img,mask)\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:27.730301Z","iopub.execute_input":"2021-10-30T11:58:27.730797Z","iopub.status.idle":"2021-10-30T11:58:27.740289Z","shell.execute_reply.started":"2021-10-30T11:58:27.730758Z","shell.execute_reply":"2021-10-30T11:58:27.739439Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=32\nEPOCHS=80","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:27.742278Z","iopub.execute_input":"2021-10-30T11:58:27.743546Z","iopub.status.idle":"2021-10-30T11:58:27.749418Z","shell.execute_reply.started":"2021-10-30T11:58:27.743505Z","shell.execute_reply":"2021-10-30T11:58:27.748652Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"aug_params=dict(\n    rotation_range=0.1,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    shear_range=0.05,\n    zoom_range=0.05,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\ntrain_dataloader=dataloader(train,BATCH_SIZE,IMG_SIZE,aug_params)\nval_dataloader=dataloader(val,BATCH_SIZE,IMG_SIZE,dict())\ntest_dataloader=dataloader(test,BATCH_SIZE,IMG_SIZE,dict())","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:27.750995Z","iopub.execute_input":"2021-10-30T11:58:27.751404Z","iopub.status.idle":"2021-10-30T11:58:27.759836Z","shell.execute_reply.started":"2021-10-30T11:58:27.751345Z","shell.execute_reply":"2021-10-30T11:58:27.758808Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## UNet Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, Conv2DTranspose\nfrom tensorflow.keras.layers import concatenate, BatchNormalization\nfrom tensorflow.keras import backend as K\n\n\nclass UNet():\n    @staticmethod\n    def build(width, height, depth):\n        input_shape=(height,width,depth)\n        channels_dim=-1\n        if K.image_data_format=='channels_first':\n            input_shape=(depth,height,width)\n            channels_dim=1\n        \n        inputs=Input(input_shape)\n        conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n        a1 = Activation('relu')(conv1)\n        bn1 = BatchNormalization(axis=channels_dim)(a1)\n        conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n        a1 = Activation('relu')(conv1)\n        bn1 = BatchNormalization(axis=channels_dim)(a1)\n        pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n        conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n        a2 = Activation('relu')(conv2)\n        bn2 = BatchNormalization(axis=channels_dim)(a2)\n        conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n        a2 = Activation('relu')(conv2)\n        bn2 = BatchNormalization(axis=channels_dim)(a2)\n        pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n        conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n        a3 = Activation('relu')(conv3)\n        bn3 = BatchNormalization(axis=channels_dim)(a3)\n        conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n        a3 = Activation('relu')(conv3)\n        bn3 = BatchNormalization(axis=channels_dim)(a3)\n        pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n        conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n        a4 = Activation('relu')(conv4)\n        bn4 = BatchNormalization(axis=channels_dim)(a4)\n        conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n        a4 = Activation('relu')(conv4)\n        bn4 = BatchNormalization(axis=channels_dim)(a4)\n        pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n        conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n        a5 = Activation('relu')(conv5)\n        bn5 = BatchNormalization(axis=channels_dim)(a5)\n        conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n        a5 = Activation('relu')(conv5)\n        bn5 = BatchNormalization(axis=channels_dim)(a5)\n        \n        up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=channels_dim)\n        conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n        a6 = Activation('relu')(conv6)\n        bn6 = BatchNormalization(axis=channels_dim)(a6)\n        conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n        a6 = Activation('relu')(conv6)\n        bn6 = BatchNormalization(axis=channels_dim)(a6)\n\n        up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=channels_dim)\n        conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n        a7 = Activation('relu')(conv7)\n        bn7 = BatchNormalization(axis=channels_dim)(a7)\n        conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n        a7 = Activation('relu')(conv7)\n        bn7 = BatchNormalization(axis=channels_dim)(a7)\n        \n        up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=channels_dim)\n        conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n        a8 = Activation('relu')(conv8)\n        bn8 = BatchNormalization(axis=channels_dim)(a8)\n        conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n        a8 = Activation('relu')(conv8)\n        bn8 = BatchNormalization(axis=channels_dim)(a8)\n        \n        up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=channels_dim)\n        conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n        a9 = Activation('relu')(conv9)\n        bn9 = BatchNormalization(axis=channels_dim)(a9)\n        conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n        a9 = Activation('relu')(conv9)\n        bn9 = BatchNormalization(axis=channels_dim)(a9)  \n\n        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n        return Model(inputs=[inputs], outputs=[conv10])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:27.761537Z","iopub.execute_input":"2021-10-30T11:58:27.761832Z","iopub.status.idle":"2021-10-30T11:58:27.795234Z","shell.execute_reply.started":"2021-10-30T11:58:27.761794Z","shell.execute_reply":"2021-10-30T11:58:27.794444Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epsilon=100\n\ndef dice_coeff(y_true, y_pred, epsilon=epsilon): \n    #flatten label and prediction tensors\n    y_pred = K.flatten(y_pred)\n    y_true = K.flatten(y_true)\n    \n    intersection = K.sum(y_true*y_pred)\n    dice = (2*intersection + epsilon) / (K.sum(y_true) + K.sum(y_pred) + epsilon)\n    return dice\n\ndef soft_dice_loss(y_true, y_pred):\n    return 1 - dice_coeff(y_true, y_pred)\n\ndef iou(y_true, y_pred, epsilon=epsilon):\n    #flatten label and prediction tensors\n    y_pred = K.flatten(y_pred)\n    y_true = K.flatten(y_true)\n    \n    intersection = K.sum(y_true*y_pred)\n    total = K.sum(y_true) + K.sum(y_pred)\n    union = total - intersection\n    \n    iou = (intersection + epsilon) / (union + epsilon)\n    return iou\n\ndef iou_loss(y_true, y_pred):\n    return 1 - iou(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:27.796586Z","iopub.execute_input":"2021-10-30T11:58:27.796949Z","iopub.status.idle":"2021-10-30T11:58:27.809071Z","shell.execute_reply.started":"2021-10-30T11:58:27.796897Z","shell.execute_reply":"2021-10-30T11:58:27.808182Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nmodel = UNet.build(IMG_SIZE[0],IMG_SIZE[1],3)\n\nLEARNING_RATE=1e-3\n\nopt = Adam(learning_rate=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)\nmodel.compile(optimizer=opt, loss=iou_loss, metrics=[iou,dice_coeff])\n\n\ncheckpoint=ModelCheckpoint(\n        filepath='/kaggle/working/weights.unet_best.hdf5', \n        monitor='val_loss',\n        verbose=1, \n        save_best_only=True\n)\nstopper=EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=15)\nreducer=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:27.811492Z","iopub.execute_input":"2021-10-30T11:58:27.812017Z","iopub.status.idle":"2021-10-30T11:58:30.495794Z","shell.execute_reply.started":"2021-10-30T11:58:27.811980Z","shell.execute_reply":"2021-10-30T11:58:30.495116Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"history=model.fit(\n    train_dataloader,\n    steps_per_epoch=TRAIN_SIZE//BATCH_SIZE,\n    validation_data=val_dataloader,\n    validation_steps=VAL_SIZE//BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[checkpoint,stopper,reducer]\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T11:58:30.497036Z","iopub.execute_input":"2021-10-30T11:58:30.497255Z","iopub.status.idle":"2021-10-30T13:22:29.866258Z","shell.execute_reply.started":"2021-10-30T11:58:30.497223Z","shell.execute_reply":"2021-10-30T13:22:29.865321Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Load the model with the best weights\n''''\nmodel = UNet.build(IMG_SIZE[0],IMG_SIZE[1],3)\nmodel.load_weights('/kaggle/working/weights.unet_best.hdf5')\nopt = Adam(learning_rate=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)\nmodel.compile(optimizer=opt, loss=iou_loss, metrics=[iou,dice_coeff])\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import floor\n\ndef plot_model_performance(history, loss, metrics):\n    plt.style.use(\"ggplot\")\n    n_epochs_trained=len(history.history['loss'])\n    metrics=[(m,'val_'+m) for m in metrics]\n    metrics.insert(0, ('loss','val_loss'))\n    row=1\n    col=2\n    number_of_plots=len(metrics)\n    if number_of_plots%2==0:\n        row=number_of_plots/2\n    else:\n        row=floor(number_of_plots/2)+1\n    \n    figure, axis = plt.subplots(row,col,figsize=(16., 10.))\n    if number_of_plots%2!=0:\n        figure.delaxes(axis[row-1,col-1])\n        \n    for r in range(row):\n        for c in range(col):\n            axis[r,c].plot(np.arange(0, n_epochs_trained), history.history[metrics[c+2*r][0]], label=\"train_\"+metrics[c+2*r][0])\n            axis[r,c].plot(np.arange(0, n_epochs_trained), history.history[metrics[c+2*r][1]], label=metrics[c+2*r][1])\n            if metrics[c+2*r][0]=='loss':\n                axis[r,c].set_title(\"Train vs Validation {} loss\".format(loss), fontsize = 15)\n            else:\n                axis[r,c].set_title(\"Train vs Validation {}\".format(metrics[c+2*r][0]), fontsize = 15)\n\n            axis[r,c].set_xlabel(\"Epoch #\")\n            axis[r,c].set_ylabel(metrics[c+2*r][0])\n            axis[r,c].legend(loc=\"lower left\")\n            if 1+c+r*2>=number_of_plots:\n                break\n    \n    figure.tight_layout(pad=3.0)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T13:47:55.911811Z","iopub.execute_input":"2021-10-30T13:47:55.912072Z","iopub.status.idle":"2021-10-30T13:47:55.924782Z","shell.execute_reply.started":"2021-10-30T13:47:55.912041Z","shell.execute_reply":"2021-10-30T13:47:55.924037Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nresults = model.evaluate(test_dataloader, steps=TEST_SIZE // BATCH_SIZE)\nprint()\nprint(\"Mean loss: {}\".format(results[0]))\nprint(\"Mean IOU score: {}\".format(results[1]))\nprint(\"Mean dice coeff: {}\".format(results[2]))\nprint()\nplot_model_performance(history,'iou',[\"iou\",\"dice_coeff\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T13:52:43.259852Z","iopub.execute_input":"2021-10-30T13:52:43.260120Z","iopub.status.idle":"2021-10-30T13:52:54.261940Z","shell.execute_reply.started":"2021-10-30T13:52:43.260088Z","shell.execute_reply":"2021-10-30T13:52:54.261246Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Results","metadata":{}},{"cell_type":"code","source":"NUMBER_OF_IMAGES=10\n\nfor i in range(NUMBER_OF_IMAGES):\n    index=np.random.randint(1,len(test.index))\n    img = cv2.imread(test['image_path'].iloc[index])\n    img = cv2.resize(img ,IMG_SIZE)\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(test['mask_path'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T13:48:27.200225Z","iopub.execute_input":"2021-10-30T13:48:27.200496Z","iopub.status.idle":"2021-10-30T13:48:33.870950Z","shell.execute_reply.started":"2021-10-30T13:48:27.200467Z","shell.execute_reply":"2021-10-30T13:48:33.870311Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Using the model as a tool","metadata":{}},{"cell_type":"code","source":"index=np.random.randint(1,len(test.index))\nimg=cv2.imread(test[\"image_path\"].iloc[index])\nimg=cv2.resize(img,IMG_SIZE)\nimg=img/255\nimg = img[np.newaxis, :, :, :]\npred=model.predict(img)\npred=np.squeeze(pred) > .5\nmask=pred!=0\nimg_mask=np.array(img)\nimg_mask[0,mask,:]=(1,0,0)\n\nfigure=plt.figure(figsize=(12,12))\nplt.subplot(1,4,1)\nplt.imshow(np.squeeze(img))\nplt.title('Original Image')\nplt.subplot(1,4,2)\nplt.imshow(np.squeeze(cv2.imread(test['mask_path'].iloc[index])))\nplt.title('Original Mask')\nplt.subplot(1,4,3)\nplt.imshow(pred)\nplt.title('Prediction')\nplt.subplot(1,4,4)\nplt.imshow(np.squeeze(img_mask))\nplt.title('Original with predicted mask')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T14:19:26.084691Z","iopub.execute_input":"2021-10-30T14:19:26.085355Z","iopub.status.idle":"2021-10-30T14:19:26.616114Z","shell.execute_reply.started":"2021-10-30T14:19:26.085317Z","shell.execute_reply":"2021-10-30T14:19:26.615357Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}